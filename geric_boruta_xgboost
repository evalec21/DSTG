import pandas as pd
import numpy as np
import seaborn as sns
import dalex as dx
from xgboost import XGBRegressor, XGBClassifier
from boruta import BorutaPy
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score

# 1. UCITAVANJE I PRIPREMA PODATAKA
print("Učitavanje podataka...")
df = sns.load_dataset('diamonds')

# Encoding kategorskih varijabli
le_color = LabelEncoder()
le_clarity = LabelEncoder()
le_cut = LabelEncoder()

df['color_enc'] = le_color.fit_transform(df['color'])
df['clarity_enc'] = le_clarity.fit_transform(df['clarity'])
df['cut_enc'] = le_cut.fit_transform(df['cut'])

# Definiranje ulaznih značajki
features = ['carat', 'depth', 'table', 'x', 'y', 'z', 'color_enc', 'clarity_enc']
X = df[features]

# --- DIO 1: REGRESIJA (Cilj: price) ---
print("\n--- REGRESIJSKI ZADATAK (XGBoost) ---")
y_reg = df['price']
X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_reg, test_size=0.2, random_state=42)

# Boruta selekcija značajki za regresiju
print("Pokrećem Boruta selekciju za regresiju (može potrajati par minuta)...")
rf_boruta_reg = RandomForestRegressor(n_jobs=-1, max_depth=5, n_estimators=50)
boruta_selector_reg = BorutaPy(rf_boruta_reg, n_estimators='auto', verbose=0, random_state=1)
boruta_selector_reg.fit(X_train_r.values, y_train_r.values)
selected_features_reg = X.columns[boruta_selector_reg.support_].tolist()
print(f"Boruta odabrane značajke za regresiju: {selected_features_reg}")

# Treniranje regresijskog modela
xgb_reg = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)
xgb_reg.fit(X_train_r[selected_features_reg], y_train_r)

# Evaluacija regresije
y_pred_r = xgb_reg.predict(X_test_r[selected_features_reg])
rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_r))
mae = mean_absolute_error(y_test_r, y_pred_r)
r2 = r2_score(y_test_r, y_pred_r)

print(f"REGRESIJA REZULTATI:")
print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"R2: {r2:.4f}")

# --- DIO 2: KLASIFIKACIJA (Cilj: cut) ---
print("\n--- KLASIFIKACIJSKI ZADATAK (XGBoost) ---")
y_cls = df['cut_enc']
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_cls, test_size=0.2, random_state=42)

# Boruta selekcija značajki za klasifikaciju (opcionalno, možeš koristiti sve značajke)
print("Pokrećem Boruta selekciju za klasifikaciju...")
rf_boruta_cls = RandomForestRegressor(n_jobs=-1, max_depth=5, n_estimators=50) # Boruta za klasifikaciju koristi RF Regressor
boruta_selector_cls = BorutaPy(rf_boruta_cls, n_estimators='auto', verbose=0, random_state=1)
boruta_selector_cls.fit(X_train_c.values, y_train_c.values) # Treba y.values biti numeri?
selected_features_cls = X.columns[boruta_selector_cls.support_].tolist()
print(f"Boruta odabrane značajke za klasifikaciju: {selected_features_cls}")

# Treniranje klasifikacijskog modela
xgb_cls = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, eval_metric='mlogloss', use_label_encoder=False)
xgb_cls.fit(X_train_c[selected_features_cls], y_train_c)

# Evaluacija klasifikacije
y_pred_c = xgb_cls.predict(X_test_c[selected_features_cls])
acc = accuracy_score(y_test_c, y_pred_c)
f1 = f1_score(y_test_c, y_pred_c, average='weighted')

print(f"KLASIFIKACIJA REZULTATI:")
print(f"Accuracy: {acc:.4f}")
print(f"F1-Score (weighted): {f1:.4f}")

# --- DIO 3: SPREMANJE REZULTATA I DALEX ---
# Spremanje metrike u CSV za usporedbu s kolegama
metrics_df = pd.DataFrame({
    'Model': ['XGBoost Regresija', 'XGBoost Klasifikacija'],
    'RMSE': [rmse, np.nan],
    'MAE': [mae, np.nan],
    'R2': [r2, np.nan],
    'Accuracy': [np.nan, acc],
    'F1_Score': [np.nan, f1]
})
metrics_df.to_csv('moje_metrike_usporedba.csv', index=False)

print("\nGeneriram HTML vizualizacije...")

# Funkcija za spremanje HTML grafova
def save_html_plots(explainer_obj, X_data_subset, prefix_name):
    # Globalna važnost značajki
    explainer_obj.model_parts().plot(show=False).write_html(f"{prefix_name}_1_Importance.html")
    
    # SHAP (za prvu opservaciju)
    obs = X_data_subset.iloc[[0]]
    explainer_obj.predict_parts(obs, type='shap').plot(show=False).write_html(f"{prefix_name}_2_SHAP.html")
    
    # Partial Dependence Plot (PDP) za 'carat'
    explainer_obj.model_profile(variables=['carat'], type='partial').plot(show=False).write_html(f"{prefix_name}_3_PDP_Carat.html")
    
    # Accumulated Local Effects (ALE) za 'carat'
    explainer_obj.model_profile(variables=['carat'], type='accumulated').plot(show=False).write_html(f"{prefix_name}_4_ALE_Carat.html")
    
    # Ceteris Paribus za 'carat'
    explainer_obj.predict_profile(obs, variables=['carat']).plot(show=False).write_html(f"{prefix_name}_5_CeterisParibus_Carat.html")
    print(f"HTML grafovi za {prefix_name} spremljeni.")

# Dalex Explainer i spremanje grafova za Regresiju
exp_reg = dx.Explainer(xgb_reg, X_test_r[selected_features_reg], y_test_r, label="XGBoost_Price")
save_html_plots(exp_reg, X_test_r[selected_features_reg], "REGRESIJA")

# Dalex Explainer i spremanje grafova za Klasifikaciju
# Upozorenje: Za klasifikaciju, y_test_c su enkodirani brojevi, DALEX ih može interpretirati.
exp_cls = dx.Explainer(xgb_cls, X_test_c[selected_features_cls], y_test_c, label="XGBoost_Cut")
save_html_plots(exp_cls, X_test_c[selected_features_cls], "KLASIFIKACIJA")

# Izvoz kompletnog procesiranog dataseta
df.to_csv('diamonds_final_processed.csv', index=False)
print("\nSVE GOTOVO!")
print("Provjeri direktorij za 'moje_metrike_usporedba.csv' i 10 HTML datoteka (5 za REGRESIJU i 5 za KLASIFIKACIJU).")
